library(PerformanceAnalytics)
library(RColorBrewer)
library(here)
library(ROSE)
library(randomForest)
library(caret)
library(rstatix)
library(gridExtra)
library(grid)
#install.packages("moments")
library(moments)
library(writexl)
metric <- c("chao1", "margalef", "menhinick", "fisher_alpha", "faith_pd", "gini_index", "strong", "pielou_evenness", "shannon_entropy", "simpson")
all_healthy <- read.csv(here("01_tidy_data", "AGP_healthy.csv.gz"), header = TRUE, sep = ",")
IBD <- read.csv(here("01_tidy_data", "IBD.csv.gz"), header = TRUE, sep = ",")
UC <- read.csv(here("01_tidy_data", "UC.csv.gz"), header = TRUE, sep = ",")
CD <- read.csv(here("01_tidy_data", "CD_2.csv.gz"), header = TRUE, sep = ",")
CDI <- read.csv(here("01_tidy_data", "ncbi_CDI.csv.gz"), header = TRUE, sep = ",")
hospital_CDI <- read.csv(here("01_tidy_data", "hosp_CDI.csv.gz"), header = TRUE, sep = ",")
hospital_donor <- read.csv(here("01_tidy_data", "hosp_donor.csv.gz"), header = TRUE, sep = ",")
all_healthy <- dplyr::select(all_healthy, sample_id, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, pielou_evenness, gini_index, strong, simpson, faith_pd, condition)
CD_merge <- CD %>%
filter(condition != "not applicable")
CD_merge$condition[CD_merge$condition=="control"] <- "healthy"
CD_merge$condition[CD_merge$condition=="crohns"] <- "CD"
healthy_disease <- rbind.fill(all_healthy, IBD, UC, CD_merge, CDI)
# extract only allpha metrics and condition columns
healthy_disease <- dplyr::select(healthy_disease, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, gini_index, strong, pielou_evenness, faith_pd, condition)
# for random forest
healthy_disease$healthy_or_not[healthy_disease$condition == "healthy"] <- "healthy"
healthy_disease$healthy_or_not[healthy_disease$condition != "healthy"] <- "unhealthy"
healthy_disease$healthy_or_not<- as.factor(healthy_disease$healthy_or_not)
healthy_disease$condition<- as.factor(healthy_disease$condition)
table(healthy_disease$condition)
table(healthy_disease$healthy_or_not)
healthy_IBD <- rbind.fill(all_healthy, IBD, UC, CD_merge)
# extract only allpha metrics and condition columns
healthy_IBD <- dplyr::select(healthy_IBD, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, gini_index, strong, pielou_evenness, faith_pd, condition)
# for random forest
healthy_IBD$healthy_or_not[healthy_IBD$condition == "healthy"] <- "healthy"
healthy_IBD$healthy_or_not[healthy_IBD$condition != "healthy"] <- "unhealthy"
healthy_IBD$healthy_or_not<- as.factor(healthy_IBD$healthy_or_not)
healthy_IBD$condition<- as.factor(healthy_IBD$condition)
table(healthy_IBD$condition)
table(healthy_IBD$healthy_or_not)
healthy_CDI <- rbind.fill(all_healthy, CDI)
# extract only allpha metrics and condition columns
healthy_CDI <- dplyr::select(healthy_CDI, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, gini_index, strong, pielou_evenness, faith_pd, condition)
# for random forest
healthy_CDI$healthy_or_not[healthy_CDI$condition == "healthy"] <- "healthy"
healthy_CDI$healthy_or_not[healthy_CDI$condition != "healthy"] <- "unhealthy"
healthy_CDI$healthy_or_not<- as.factor(healthy_CDI$healthy_or_not)
healthy_CDI$condition<- as.factor(healthy_CDI$condition)
table(healthy_CDI$condition)
table(healthy_CDI$healthy_or_not)
hospital_CDI_pre_FMT <- hospital_CDI %>%
filter(FMT_pre_post == "pre")
compare_hospital <- rbind.fill(hospital_donor, hospital_CDI_pre_FMT)
compare_hospital$condition <- as.factor(compare_hospital$condition)
# Sizes of each dataset
table(compare_hospital$condition)
# Let's make training and testing subset of data
#make this example reproducible
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(healthy_disease), replace=TRUE, prob=c(0.7,0.3))
train  <- healthy_disease[sample, ]
test   <- healthy_disease[!sample, ]
table(train$healthy_or_not)
# condition groups are unbalanced. We will solve this by undersampling
under <- ovun.sample(healthy_or_not~., data=train, method = "under", p=0.5)
train <- under$data
table(train$healthy_or_not)
richness <- c("chao1", "margalef", "menhinick", "fisher_alpha", "faith_pd")
evenness <- c("gini_index", "strong", "pielou_evenness", "shannon_entropy", "simpson")
results_accuracy_all <- data.frame(model = character(0), accuracy = numeric(0) )
model_all_1 <- randomForest(condition ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
model_all_2 <- randomForest(healthy_or_not ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
prediction_all_1 <- predict(model_all_1, test)
confusion_matrix <- confusionMatrix(prediction_all_1, test$condition)
accuracy_all_model_1 <- confusion_matrix$overall["Accuracy"]
prediction_all_2 <- predict(model_all_2, test)
confusion_matrix <- confusionMatrix(prediction_all_2, test$healthy_or_not)
accuracy_all_model_2 <- confusion_matrix$overall["Accuracy"]
for (a in richness){
for (b in evenness){
formula_1 <- as.formula(sprintf("%s ~ %s + %s", "condition", a, b))
model_1 <- randomForest(formula_1, data = train, importance=TRUE)
formula_2 <- as.formula(sprintf("%s ~ %s + %s", "healthy_or_not", a, b))
model_2 <- randomForest(formula_2, data = train, importance=TRUE)
# Calculating accuracy
prediction_1 <- predict(model_1, test)
confusion_matrix <- confusionMatrix(prediction_1, test$condition)
accuracy_1 <- confusion_matrix$overall["Accuracy"]
prediction_2 <- predict(model_2, test)
confusion_matrix <- confusionMatrix(prediction_2, test$healthy_or_not)
accuracy_2 <- confusion_matrix$overall["Accuracy"]
new_row <- c(model = sprintf("%s + %s", a, b), accuracy_condition = accuracy_1, accuracy_healthy_or_not = accuracy_2)
results_accuracy_all <- rbind(results_accuracy_all, new_row)
}
}
names(results_accuracy_all)[1] <- 'model'
names(results_accuracy_all)[2] <- 'accuracy_condition'
names(results_accuracy_all)[3] <- 'accuracy_healthy_or_not'
results_accuracy_all[nrow(results_accuracy_all)+1,] <- c("all alpha metrics", accuracy_all_model_1, accuracy_all_model_2)
results_accuracy_all$accuracy_condition <- as.numeric(results_accuracy_all$accuracy_condition)
results_accuracy_all$accuracy_healthy_or_not <- as.numeric(results_accuracy_all$accuracy_healthy_or_not)
results_accuracy_all <- results_accuracy_all[order(-results_accuracy_all$accuracy_condition),]
results_accuracy_all[1:10,] %>%
flextable() %>%
add_header_lines(values = "Accuracy of random forest classifier trained on all datasets in differnet models")
write_xlsx(results_accuracy_all, here("03_plots_and_tables", "accuracy_all.xlsx"))
# Let's make training and testing subset of data
#make this example reproducible
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(healthy_IBD), replace=TRUE, prob=c(0.7,0.3))
train  <- healthy_IBD[sample, ]
test   <- healthy_IBD[!sample, ]
table(train$healthy_or_not)
# condition groups are unbalanced. We will solve this by undersampling
under <- ovun.sample(healthy_or_not~., data=train, method = "under", p=0.5)
train <- under$data
table(train$healthy_or_not)
table(train$condition)
results_accuracy_IBD <- data.frame(model = character(0), accuracy_condition = numeric(0), accuracy_healthy_or_not = numeric(0) )
model_IBD_1 <- randomForest(condition ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
model_IBD_2 <- randomForest(healthy_or_not ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
prediction_IBD_1 <- predict(model_IBD_1, test)
confusion_matrix <- confusionMatrix(prediction_IBD_1, test$condition)
accuracy_IBD_model_1 <- confusion_matrix$overall["Accuracy"]
prediction_IBD_2 <- predict(model_IBD_2, test)
confusion_matrix <- confusionMatrix(prediction_IBD_2, test$healthy_or_not)
accuracy_IBD_model_2 <- confusion_matrix$overall["Accuracy"]
for (a in richness){
for (b in evenness){
formula_1 <- as.formula(sprintf("%s ~ %s + %s", "condition", a, b))
model_1 <- randomForest(formula_1, data = train, importance=TRUE)
formula_2 <- as.formula(sprintf("%s ~ %s + %s", "healthy_or_not", a, b))
model_2 <- randomForest(formula_2, data = train, importance=TRUE)
# Calculating accuracy
prediction_1 <- predict(model_1, test)
confusion_matrix <- confusionMatrix(prediction_1, test$condition)
accuracy_1 <- confusion_matrix$overall["Accuracy"]
prediction_2 <- predict(model_2, test)
confusion_matrix <- confusionMatrix(prediction_2, test$healthy_or_not)
accuracy_2 <- confusion_matrix$overall["Accuracy"]
new_row <- c(model = sprintf("%s + %s", a, b), accuracy_condition = accuracy_1, accuracy_healthy_or_not = accuracy_2)
results_accuracy_IBD <- rbind(results_accuracy_IBD, new_row)
}
}
names(results_accuracy_IBD)[1] <- 'model'
names(results_accuracy_IBD)[2] <- 'accuracy_condition'
names(results_accuracy_IBD)[3] <- 'accuracy_healthy_or_not'
results_accuracy_IBD[nrow(results_accuracy_IBD)+1,] <- c("all alpha metrics", accuracy_IBD_model_1, accuracy_IBD_model_2)
results_accuracy_IBD$accuracy_condition <- as.numeric(results_accuracy_IBD$accuracy_condition)
results_accuracy_IBD$accuracy_healthy_or_not <- as.numeric(results_accuracy_IBD$accuracy_healthy_or_not)
results_accuracy_IBD <- results_accuracy_IBD[order(-results_accuracy_IBD$accuracy_condition),]
results_accuracy_IBD[1:10,] %>%
flextable() %>%
add_header_lines(values = "Accuracy of random forest classifier trained on IBD and healthy datasets in differnet models")
write_xlsx(results_accuracy_IBD, here("03_plots_and_tables", "accuracy_IBD.xlsx"))
# Let's make training and testing subset of data
#make this example reproducible
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(healthy_CDI), replace=TRUE, prob=c(0.7,0.3))
train  <- healthy_CDI[sample, ]
test   <- healthy_CDI[!sample, ]
table(train$condition)
# condition groups are unbalanced. We will solve this by undersampling
under <- ovun.sample(condition~., data=train, method = "under", p=0.5)
train <- under$data
table(train$condition)
results_accuracy_CDI <- data.frame(model = character(0), accuracy = numeric(0))
model_all <- randomForest(condition ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
prediction_CDI_all <- predict(model_all, test)
confusion_matrix <- confusionMatrix(prediction_CDI_all, test$condition)
accuracy_CDI_all <- confusion_matrix$overall["Accuracy"]
for (a in richness){
for (b in evenness){
formula <- as.formula(sprintf("%s ~ %s + %s", "condition", a, b))
model <- randomForest(formula, data = train, importance=TRUE)
# Calculating accuracy
prediction <- predict(model, test)
confusion_matrix <- confusionMatrix(prediction, test$condition)
accuracy <- confusion_matrix$overall["Accuracy"]
new_row <- c(model = sprintf("%s + %s", a, b), accuracy = accuracy)
results_accuracy_CDI <- rbind(results_accuracy_CDI, new_row)
}
}
names(results_accuracy_CDI)[1] <- 'model'
names(results_accuracy_CDI)[2] <- 'accuracy'
results_accuracy_CDI[nrow(results_accuracy_CDI)+1,] <- c("all alpha metrics", accuracy_CDI_all)
results_accuracy_CDI$accuracy <- as.numeric(results_accuracy_CDI$accuracy)
results_accuracy_CDI <- results_accuracy_CDI[order(-results_accuracy_CDI$accuracy),]
results_accuracy_CDI[1:10,] %>%
flextable() %>%
add_header_lines(values = "Accuracy of random forest classifier trained on CDI and healthy datasets in differnet models")
write_xlsx(results_accuracy_CDI, here("03_plots_and_tables", "accuracy_CDI.xlsx"))
model <- randomForest(condition ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = healthy_disease, importance=TRUE)
importance(model)
varImpPlot(model, main= "Mean descrease in accuracy and  Gini index over all classes")
#Conditional=True, adjusts for correlations between predictors.
i_scores <- caret::varImp(model, conditional = TRUE)
#Gathering rownames in 'var'  and converting it to the factor
#to provide 'fill' parameter for the bar chart.
i_scores <- i_scores %>% tibble::rownames_to_column("var")
i_scores$var<- i_scores$var %>% as.factor()
#Plotting the bar and polar charts for comparing variables
importance_plot <- i_scores %>% ggplot(aes(x = .data[["healthy"]], y=reorder(var, .data[["healthy"]]), fill = var)) +
geom_bar(stat = "identity", show.legend = FALSE, width = 1) +
labs(x = NULL, y = NULL, title ="Mean decrease in accuracy for condition category: healthy") +
theme_minimal() +
theme(axis.text.y = element_text(size=15)) +
# theme(axis.text.y = element_blank()) +
scale_y_discrete(labels=c("shannon_entropy"="Shannon entropy (❋)", "chao1"="Chao1 (+)", "menhinick"="Menhinick (+)", "margalef"="Margalef (+)", "fisher_alpha"="Fisher alpha (+)", "simpson"="Simpson (❋)", "gini_index"="Gini index (x)", "strong"="Strong dominance (x)", "pielou_evenness"="Pielou evenness (x)",  "faith_pd"="Faith PD (+)"))
importance_plot
# Let's make training and testing subset of data
#make this example reproducible
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(compare_hospital), replace=TRUE, prob=c(0.7,0.3))
train  <- compare_hospital[sample, ]
test   <- compare_hospital[!sample, ]
table(train$condition)
table(test$condition)
results_accuracy_CDI_hospital <- data.frame(model = character(0), accuracy = numeric(0))
model_all_hospital <- randomForest(condition ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
prediction_CDI_all <- predict(model_all_hospital, test)
confusion_matrix <- confusionMatrix(prediction_CDI_all, test$condition)
accuracy_CDI_all <- confusion_matrix$overall["Accuracy"]
for (a in richness){
for (b in evenness){
formula <- as.formula(sprintf("%s ~ %s + %s", "condition", a, b))
model <- randomForest(formula, data = train, importance=TRUE)
# Calculating accuracy
prediction <- predict(model, test)
confusion_matrix <- confusionMatrix(prediction, test$condition)
accuracy <- confusion_matrix$overall["Accuracy"]
new_row <- c(model = sprintf("%s + %s", a, b), accuracy = accuracy)
results_accuracy_CDI_hospital <- rbind(results_accuracy_CDI_hospital, new_row)
}
}
names(results_accuracy_CDI_hospital)[1] <- 'model'
names(results_accuracy_CDI_hospital)[2] <- 'accuracy'
results_accuracy_CDI_hospital[nrow(results_accuracy_CDI_hospital)+1,] <- c("all alpha metrics", accuracy_CDI_all)
results_accuracy_CDI_hospital$accuracy <- as.numeric(results_accuracy_CDI_hospital$accuracy)
results_accuracy_CDI <- results_accuracy_CDI[order(-results_accuracy_CDI_hospital$accuracy),]
results_accuracy_CDI_hospital[1:10,] %>%
flextable() %>%
add_header_lines(values = "Accuracy of random forest classifier trained on CDI and healthy datasets in differnet models")
write_xlsx(results_accuracy_CDI_hospital, here("03_plots_and_tables", "accuracy_CDI_hospital.xlsx"))
table(healthy_disease$healthy_or_not)
test <- list()
tibble <- tibble()
for (i in 1:length(metric)){
# Wilcoxon test
test[[i]] <- pairwise.wilcox.test(healthy_disease[[metric[i]]], healthy_disease$healthy_or_not, p.adjust.method="none") %>%
broom::tidy() %>% add_column(parameter = metric[i], .before='group1')
test[[i]]$p.value <- round(test[[i]]$p.value, digits = 16)
# Effect size
tibble_a <- healthy_disease %>% wilcox_effsize(
as.formula(sprintf("%s ~ %s", metric[i], "healthy_or_not")),
ref.group = "healthy",
paired = FALSE,
alternative = "two.sided",
ci = TRUE,
conf.level = 0.95,
ci.type = "perc",
nboot = 1000
)
tibble <- bind_rows(tibble, tibble_a)
}
tests_1 <- do.call(what = rbind, args = test)
names(tibble)[names(tibble) == '.y.'] <- 'parameter'
eff_size <- tibble[, !names(tibble) %in% c("group1", "group2")]
tests_1 <- inner_join(tests_1, eff_size , by= "parameter")
test_1_show <- tests_1 %>%
# add_column(p.adjusted = round(p.adjust(tests_1$p.value, "fdr"), 16), .after='p.value') %>%
add_column(p.adjusted = p.adjust(tests_1$p.value, "fdr"), .after='p.value') %>%
arrange(-effsize)
test_1_show %>%
flextable() %>%
bold(~ p.value < 0.05, 4) %>%
bold(~ p.adjusted < 0.05, 5) %>%
add_header_lines(values = "Results of the Wilcox test for distributions of healthy vs unhealthy samples")
#write.csv(tests_1, gzfile(here("03_plots_and_tables", "eff_size.csv")), row.names=FALSE)
#install.packages("writexl")
library(writexl)
write_xlsx(test_1_show, here("03_plots_and_tables", "eff_size.xlsx"))
test_1_show
test <- list()
tibble <- tibble()
for (i in 1:length(metric)){
# Wilcoxon test
test[[i]] <- pairwise.wilcox.test(healthy_disease[[metric[i]]], healthy_disease$healthy_or_not, p.adjust.method="none") %>%
broom::tidy() %>% add_column(parameter = metric[i], .before='group1')
# test[[i]]$p.value <- round(test[[i]]$p.value, digits = 16)
# Effect size
tibble_a <- healthy_disease %>% wilcox_effsize(
as.formula(sprintf("%s ~ %s", metric[i], "healthy_or_not")),
ref.group = "healthy",
paired = FALSE,
alternative = "two.sided",
ci = TRUE,
conf.level = 0.95,
ci.type = "perc",
nboot = 1000
)
tibble <- bind_rows(tibble, tibble_a)
}
tests_1 <- do.call(what = rbind, args = test)
names(tibble)[names(tibble) == '.y.'] <- 'parameter'
eff_size <- tibble[, !names(tibble) %in% c("group1", "group2")]
tests_1 <- inner_join(tests_1, eff_size , by= "parameter")
test_1_show <- tests_1 %>%
# add_column(p.adjusted = round(p.adjust(tests_1$p.value, "fdr"), 16), .after='p.value') %>%
add_column(p.adjusted = p.adjust(tests_1$p.value, "fdr"), .after='p.value') %>%
arrange(-effsize)
test_1_show %>%
flextable() %>%
bold(~ p.value < 0.05, 4) %>%
bold(~ p.adjusted < 0.05, 5) %>%
add_header_lines(values = "Results of the Wilcox test for distributions of healthy vs unhealthy samples")
#write.csv(tests_1, gzfile(here("03_plots_and_tables", "eff_size.csv")), row.names=FALSE)
#install.packages("writexl")
library(writexl)
write_xlsx(test_1_show, here("03_plots_and_tables", "eff_size.xlsx"))
source("05_functions/make_reports.R")
report("02_R_scripts/Healthy_data_analysis.Rmd", "3")
report("02_R_scripts/Compare_datasets.Rmd", "4")
report("02_R_scripts/choice_of_alpha.Rmd", "5")
report("02_R_scripts/Healthy_data_analysis.Rmd", "3")
report("02_R_scripts/Compare_datasets.Rmd", "4")
report("02_R_scripts/choice_of_alpha.Rmd", "5")
report("02_R_scripts/Hospital_Clinic_data_analysis.Rmd", "6")
report("02_R_scripts/Hospital_Clinic_data_analysis.Rmd", "6")
knitr::opts_chunk$set(echo = TRUE)
train
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(plyr)
library(cowplot)
library(tibble)
library(flextable)
library(nortest)
library(corrplot)
library(PerformanceAnalytics)
library(RColorBrewer)
library(here)
library(ROSE)
library(randomForest)
library(caret)
library(rstatix)
library(gridExtra)
library(grid)
#install.packages("moments")
library(moments)
library(writexl)
metric <- c("chao1", "margalef", "menhinick", "fisher_alpha", "faith_pd", "gini_index", "strong", "pielou_evenness", "shannon_entropy", "simpson")
all_healthy <- read.csv(here("01_tidy_data", "AGP_healthy.csv.gz"), header = TRUE, sep = ",")
IBD <- read.csv(here("01_tidy_data", "IBD.csv.gz"), header = TRUE, sep = ",")
UC <- read.csv(here("01_tidy_data", "UC.csv.gz"), header = TRUE, sep = ",")
CD <- read.csv(here("01_tidy_data", "CD_2.csv.gz"), header = TRUE, sep = ",")
CDI <- read.csv(here("01_tidy_data", "ncbi_CDI.csv.gz"), header = TRUE, sep = ",")
hospital_CDI <- read.csv(here("01_tidy_data", "hosp_CDI.csv.gz"), header = TRUE, sep = ",")
hospital_donor <- read.csv(here("01_tidy_data", "hosp_donor.csv.gz"), header = TRUE, sep = ",")
all_healthy <- dplyr::select(all_healthy, sample_id, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, pielou_evenness, gini_index, strong, simpson, faith_pd, condition)
CD_merge <- CD %>%
filter(condition != "not applicable")
CD_merge$condition[CD_merge$condition=="control"] <- "healthy"
CD_merge$condition[CD_merge$condition=="crohns"] <- "CD"
healthy_disease <- rbind.fill(all_healthy, IBD, UC, CD_merge, CDI)
# extract only allpha metrics and condition columns
healthy_disease <- dplyr::select(healthy_disease, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, gini_index, strong, pielou_evenness, faith_pd, condition)
# for random forest
healthy_disease$healthy_or_not[healthy_disease$condition == "healthy"] <- "healthy"
healthy_disease$healthy_or_not[healthy_disease$condition != "healthy"] <- "unhealthy"
healthy_disease$healthy_or_not<- as.factor(healthy_disease$healthy_or_not)
healthy_disease$condition<- as.factor(healthy_disease$condition)
table(healthy_disease$condition)
table(healthy_disease$healthy_or_not)
healthy_IBD <- rbind.fill(all_healthy, IBD, UC, CD_merge)
# extract only allpha metrics and condition columns
healthy_IBD <- dplyr::select(healthy_IBD, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, gini_index, strong, pielou_evenness, faith_pd, condition)
# for random forest
healthy_IBD$healthy_or_not[healthy_IBD$condition == "healthy"] <- "healthy"
healthy_IBD$healthy_or_not[healthy_IBD$condition != "healthy"] <- "unhealthy"
healthy_IBD$healthy_or_not<- as.factor(healthy_IBD$healthy_or_not)
healthy_IBD$condition<- as.factor(healthy_IBD$condition)
table(healthy_IBD$condition)
table(healthy_IBD$healthy_or_not)
healthy_CDI <- rbind.fill(all_healthy, CDI)
# extract only allpha metrics and condition columns
healthy_CDI <- dplyr::select(healthy_CDI, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, gini_index, strong, pielou_evenness, faith_pd, condition)
# for random forest
healthy_CDI$healthy_or_not[healthy_CDI$condition == "healthy"] <- "healthy"
healthy_CDI$healthy_or_not[healthy_CDI$condition != "healthy"] <- "unhealthy"
healthy_CDI$healthy_or_not<- as.factor(healthy_CDI$healthy_or_not)
healthy_CDI$condition<- as.factor(healthy_CDI$condition)
table(healthy_CDI$condition)
table(healthy_CDI$healthy_or_not)
hospital_CDI_pre_FMT <- hospital_CDI %>%
filter(FMT_pre_post == "pre")
compare_hospital <- rbind.fill(hospital_donor, hospital_CDI_pre_FMT)
compare_hospital$condition <- as.factor(compare_hospital$condition)
# Sizes of each dataset
table(compare_hospital$condition)
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(healthy_disease), replace=TRUE, prob=c(0.7,0.3))
train  <- healthy_disease[sample, ]
test   <- healthy_disease[!sample, ]
table(train$healthy_or_not)
train
sample
source("05_functions/make_reports.R")
report("02_R_scripts/Hospital_Clinic_data_analysis.Rmd", "6")
source("05_functions/make_reports.R")
report("02_R_scripts/choice_of_alpha.Rmd", "5")
under
# condition groups are unbalanced. We will solve this by undersampling
under <- ovun.sample(healthy_or_not~., data=train, method = "under", p=0.5)
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(healthy_disease), replace=TRUE, prob=c(0.7,0.3))
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(plyr)
library(cowplot)
library(tibble)
library(flextable)
library(nortest)
library(corrplot)
library(PerformanceAnalytics)
library(RColorBrewer)
library(here)
library(ROSE)
library(randomForest)
library(caret)
library(rstatix)
library(gridExtra)
library(grid)
#install.packages("moments")
library(moments)
library(writexl)
metric <- c("chao1", "margalef", "menhinick", "fisher_alpha", "faith_pd", "gini_index", "strong", "pielou_evenness", "shannon_entropy", "simpson")
all_healthy <- read.csv(here("01_tidy_data", "AGP_healthy.csv.gz"), header = TRUE, sep = ",")
IBD <- read.csv(here("01_tidy_data", "IBD.csv.gz"), header = TRUE, sep = ",")
UC <- read.csv(here("01_tidy_data", "UC.csv.gz"), header = TRUE, sep = ",")
CD <- read.csv(here("01_tidy_data", "CD_2.csv.gz"), header = TRUE, sep = ",")
CDI <- read.csv(here("01_tidy_data", "ncbi_CDI.csv.gz"), header = TRUE, sep = ",")
hospital_CDI <- read.csv(here("01_tidy_data", "hosp_CDI.csv.gz"), header = TRUE, sep = ",")
hospital_donor <- read.csv(here("01_tidy_data", "hosp_donor.csv.gz"), header = TRUE, sep = ",")
all_healthy <- dplyr::select(all_healthy, sample_id, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, pielou_evenness, gini_index, strong, simpson, faith_pd, condition)
CD_merge <- CD %>%
filter(condition != "not applicable")
CD_merge$condition[CD_merge$condition=="control"] <- "healthy"
CD_merge$condition[CD_merge$condition=="crohns"] <- "CD"
healthy_disease <- rbind.fill(all_healthy, IBD, UC, CD_merge, CDI)
# extract only allpha metrics and condition columns
healthy_disease <- dplyr::select(healthy_disease, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, gini_index, strong, pielou_evenness, faith_pd, condition)
# for random forest
healthy_disease$healthy_or_not[healthy_disease$condition == "healthy"] <- "healthy"
healthy_disease$healthy_or_not[healthy_disease$condition != "healthy"] <- "unhealthy"
healthy_disease$healthy_or_not<- as.factor(healthy_disease$healthy_or_not)
healthy_disease$condition<- as.factor(healthy_disease$condition)
table(healthy_disease$condition)
table(healthy_disease$healthy_or_not)
healthy_IBD <- rbind.fill(all_healthy, IBD, UC, CD_merge)
# extract only allpha metrics and condition columns
healthy_IBD <- dplyr::select(healthy_IBD, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, gini_index, strong, pielou_evenness, faith_pd, condition)
# for random forest
healthy_IBD$healthy_or_not[healthy_IBD$condition == "healthy"] <- "healthy"
healthy_IBD$healthy_or_not[healthy_IBD$condition != "healthy"] <- "unhealthy"
healthy_IBD$healthy_or_not<- as.factor(healthy_IBD$healthy_or_not)
healthy_IBD$condition<- as.factor(healthy_IBD$condition)
table(healthy_IBD$condition)
table(healthy_IBD$healthy_or_not)
healthy_CDI <- rbind.fill(all_healthy, CDI)
# extract only allpha metrics and condition columns
healthy_CDI <- dplyr::select(healthy_CDI, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, gini_index, strong, pielou_evenness, faith_pd, condition)
# for random forest
healthy_CDI$healthy_or_not[healthy_CDI$condition == "healthy"] <- "healthy"
healthy_CDI$healthy_or_not[healthy_CDI$condition != "healthy"] <- "unhealthy"
healthy_CDI$healthy_or_not<- as.factor(healthy_CDI$healthy_or_not)
healthy_CDI$condition<- as.factor(healthy_CDI$condition)
table(healthy_CDI$condition)
table(healthy_CDI$healthy_or_not)
hospital_CDI_pre_FMT <- hospital_CDI %>%
filter(FMT_pre_post == "pre")
compare_hospital <- rbind.fill(hospital_donor, hospital_CDI_pre_FMT)
compare_hospital$condition <- as.factor(compare_hospital$condition)
# Sizes of each dataset
table(compare_hospital$condition)
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(healthy_disease), replace=TRUE, prob=c(0.7,0.3))
train  <- healthy_disease[sample, ]
test   <- healthy_disease[!sample, ]
table(train$healthy_or_not)
# condition groups are unbalanced. We will solve this by undersampling
under <- ovun.sample(healthy_or_not~., data=train, method = "under", p=0.5)
train <- under$data
table(train$healthy_or_not)
under
report("02_R_scripts/choice_of_alpha.Rmd", "5")
source("05_functions/make_reports.R")
report("02_R_scripts/choice_of_alpha.Rmd", "5")

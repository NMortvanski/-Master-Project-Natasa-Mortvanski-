confusion_matrix <- confusionMatrix(prediction_CDI_all, test$condition)
accuracy_CDI_all <- confusion_matrix$overall["Accuracy"]
for (a in richness){
for (b in evenness){
formula <- as.formula(sprintf("%s ~ %s + %s", "condition", a, b))
model <- randomForest(formula, data = train, importance=TRUE)
# Calculating accuracy
prediction <- predict(model, test)
confusion_matrix <- confusionMatrix(prediction, test$condition)
accuracy <- confusion_matrix$overall["Accuracy"]
new_row <- c(model = sprintf("%s + %s", a, b), accuracy = accuracy)
results_accuracy_CDI <- rbind(results_accuracy_CDI, new_row)
}
}
names(results_accuracy_CDI)[1] <- 'model'
names(results_accuracy_CDI)[2] <- 'accuracy'
results_accuracy_CDI[nrow(results_accuracy_CDI)+1,] <- c("all alpha metrics", accuracy_CDI_all)
results_accuracy_CDI$accuracy <- as.numeric(results_accuracy_CDI$accuracy)
results_accuracy_CDI <- results_accuracy_CDI[order(-results_accuracy_CDI$accuracy),]
results_accuracy_CDI[1:10,] %>%
flextable() %>%
add_header_lines(values = "Accuracy of random forest classifier trained on CDI and healthy datasets in differnet models")
model <- randomForest(condition ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = healthy_disease, importance=TRUE)
importance(model)
varImpPlot(model, main= "Mean descrease in accuracy and  Gini index over all classes")
#Conditional=True, adjusts for correlations between predictors.
i_scores <- caret::varImp(model, conditional = TRUE)
#Gathering rownames in 'var'  and converting it to the factor
#to provide 'fill' parameter for the bar chart.
i_scores <- i_scores %>% tibble::rownames_to_column("var")
i_scores$var<- i_scores$var %>% as.factor()
#Plotting the bar and polar charts for comparing variables
importance_plot <- i_scores %>% ggplot(aes(x = .data[["healthy"]], y=reorder(var, .data[["healthy"]]), fill = var)) +
geom_bar(stat = "identity", show.legend = FALSE, width = 1) +
labs(x = NULL, y = NULL, title ="Mean descrease in accuracy for condition category: healthy") +
theme_minimal()
importance_plot
# Let's make training and testing subset of data
#make this example reproducible
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(compare_hospital), replace=TRUE, prob=c(0.7,0.3))
train  <- compare_hospital[sample, ]
test   <- compare_hospital[!sample, ]
table(train$condition)
table(test$condition)
results_accuracy_CDI <- data.frame(model = character(0), accuracy = numeric(0))
model_all_hospital <- randomForest(condition ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
prediction_CDI_all <- predict(model_all_hospital, test)
confusion_matrix <- confusionMatrix(prediction_CDI_all, test$condition)
accuracy_CDI_all <- confusion_matrix$overall["Accuracy"]
for (a in richness){
for (b in evenness){
formula <- as.formula(sprintf("%s ~ %s + %s", "condition", a, b))
model <- randomForest(formula, data = train, importance=TRUE)
# Calculating accuracy
prediction <- predict(model, test)
confusion_matrix <- confusionMatrix(prediction, test$condition)
accuracy <- confusion_matrix$overall["Accuracy"]
new_row <- c(model = sprintf("%s + %s", a, b), accuracy = accuracy)
results_accuracy_CDI <- rbind(results_accuracy_CDI, new_row)
}
}
names(results_accuracy_CDI)[1] <- 'model'
names(results_accuracy_CDI)[2] <- 'accuracy'
results_accuracy_CDI[nrow(results_accuracy_CDI)+1,] <- c("all alpha metrics", accuracy_CDI_all)
results_accuracy_CDI$accuracy <- as.numeric(results_accuracy_CDI$accuracy)
results_accuracy_CDI <- results_accuracy_CDI[order(-results_accuracy_CDI$accuracy),]
results_accuracy_CDI[1:10,] %>%
flextable() %>%
add_header_lines(values = "Accuracy of random forest classifier trained on CDI and healthy datasets in differnet models")
table(healthy_disease$healthy_or_not)
test <- list()
tibble <- tibble()
for (i in 1:length(metric)){
# Wilcoxon test
test[[i]] <- pairwise.wilcox.test(healthy_disease[[metric[i]]], healthy_disease$healthy_or_not, p.adjust.method="none") %>%
broom::tidy() %>% add_column(parameter = metric[i], .before='group1')
test[[i]]$p.value <- round(test[[i]]$p.value, digits = 5)
# Effect size
tibble_a <- healthy_disease %>% wilcox_effsize(
as.formula(sprintf("%s ~ %s", metric[i], "healthy_or_not")),
ref.group = "healthy",
paired = FALSE,
alternative = "two.sided",
ci = TRUE,
conf.level = 0.95,
ci.type = "perc",
nboot = 1000
)
tibble <- bind_rows(tibble, tibble_a)
}
tests_1 <- do.call(what = rbind, args = test)
names(tibble)[names(tibble) == '.y.'] <- 'parameter'
eff_size <- tibble[, !names(tibble) %in% c("group1", "group2")]
tests_1 <- inner_join(tests_1, eff_size , by= "parameter")
test_1_show <- tests_1 %>%
add_column(p.adjusted = round(p.adjust(tests_1$p.value, "fdr"), 5), .after='p.value') %>%
arrange(-effsize)
test_1_show %>%
flextable() %>%
bold(~ p.value < 0.05, 4) %>%
bold(~ p.adjusted < 0.05, 5) %>%
add_header_lines(values = "Results of the Wilcox test for distributions of healthy vs unhealthy samples")
#write.csv(tests_1, gzfile(here("03_plots_and_tables", "eff_size.csv")), row.names=FALSE)
#install.packages("writexl")
library(writexl)
write_xlsx(test_1_show, here("03_plots_and_tables", "eff_size.xlsx"))
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(healthy_disease), replace=TRUE, prob=c(0.7,0.3))
train  <- healthy_disease[sample, ]
test   <- healthy_disease[!sample, ]
# condition groups are unbalanced. We will solve this by undersampling
under <- ovun.sample(healthy_or_not~., data=train, method = "under", p=0.5)
train <- under$data
test <- list()
tibble <- tibble()
for (i in 1:length(metric)){
# Wilcoxon test
test[[i]] <- pairwise.wilcox.test(train[[metric[i]]], train$healthy_or_not, p.adjust.method="none") %>%
broom::tidy() %>% add_column(parameter = metric[i], .before='group1')
test[[i]]$p.value <- round(test[[i]]$p.value, digits = 5)
# Effect size
tibble_a <- train %>% wilcox_effsize(
as.formula(sprintf("%s ~ %s", metric[i], "healthy_or_not")),
ref.group = "healthy",
paired = FALSE,
alternative = "two.sided",
ci = TRUE,
conf.level = 0.95,
ci.type = "perc",
nboot = 1000
)
tibble <- bind_rows(tibble, tibble_a)
}
tests_1b <- do.call(what = rbind, args = test)
names(tibble)[names(tibble) == '.y.'] <- 'parameter'
eff_size <- tibble[, !names(tibble) %in% c("group1", "group2")]
tests_alla <- inner_join(tests_1b, eff_size , by= "parameter")
tests_alla %>%
add_column(p.adjusted = round(p.adjust(tests_alla$p.value, "fdr"),5), .after='p.value') %>%
arrange(-effsize)  %>%
flextable() %>%
bold(~ p.value < 0.05, 4) %>%
bold(~ p.adjusted < 0.05, 5) %>%
add_header_lines(values = "Results of the Wilcox test for distributions of healthy vs unhealthy samples in balanced subset of data")
test <- list()
tibble <- tibble()
for (i in 1:length(metric)){
# Wilcoxon test
test[[i]] <- pairwise.wilcox.test(compare_hospital[[metric[i]]], compare_hospital$condition, p.adjust.method="none") %>%
broom::tidy() %>% add_column(parameter = metric[i], .before='group1')
test[[i]]$p.value <- round(test[[i]]$p.value, digits = 5)
# Effect size
tibble_a <- compare_hospital %>% wilcox_effsize(
as.formula(sprintf("%s ~ %s", metric[i], "condition")),
ref.group = "healthy_donors",
paired = FALSE,
alternative = "two.sided",
ci = TRUE,
conf.level = 0.95,
ci.type = "perc",
nboot = 1000
)
tibble <- bind_rows(tibble, tibble_a)
}
tests_1 <- do.call(what = rbind, args = test)
names(tibble)[names(tibble) == '.y.'] <- 'parameter'
eff_size <- tibble[, !names(tibble) %in% c("group1", "group2")]
tests_1 <- inner_join(tests_1, eff_size , by= "parameter")
tests_1 %>%
add_column(p.adjusted = round(p.adjust(tests_1$p.value, "fdr"), 5), .after='p.value') %>%
arrange(-effsize)  %>%
flextable() %>%
bold(~ p.value < 0.05, 4) %>%
bold(~ p.adjusted < 0.05, 5) %>%
add_header_lines(values = "Results of the Wilcox test for distributions of healthy donors vs CDI samples from Hospital CLinic")
test <- list()
for (i in 1:length(metric)){
test[[i]] <- pairwise.wilcox.test(healthy_disease[[metric[i]]], healthy_disease$condition, p.adjust.method="none") %>%
broom::tidy() %>% add_column(parameter = metric[i], .before='group1')
test[[i]]$p.value <- round(test[[i]]$p.value, digits = 5)
}
tests_2 <- do.call(what = rbind, args = test)
tests_2 %>%
add_column(p.adjusted = round(p.adjust(tests_2$p.value, "fdr"),5), .after='p.value') %>%
arrange(p.value)  %>%
filter(group1=="healthy" | group2=="healthy") %>%
flextable() %>%
bold(~ p.value < 0.05, 4) %>%
bold(~ p.adjusted < 0.05, 5) %>%
add_header_lines(values = "Results of the Wilcox test for distributions of different conditions")
set.seed(1)
#use 70% of dataset as healthy population and 30% as healthy samples to test
sample <- sample(c(TRUE, FALSE), nrow(all_healthy), replace=TRUE, prob=c(0.7,0.3))
healthy_popul  <- all_healthy[sample, ]
healthy_test   <- all_healthy[!sample, ]
nrow(healthy_popul)
nrow(healthy_test)
# samples to test
test_samples <- rbind.fill(healthy_test, CDI)
test_samples$condition <- as.factor(test_samples$condition)
test_samples$condition <- relevel(test_samples$condition, "healthy")
#test_samples <- rbind.fill(healthy_popul, CDI)
nrow(test_samples)
library(table1)
CrawfordHowell <- function(case, control){
tval <- (case - mean(control)) / (sd(control)*sqrt((length(control)+1) / length(control)))
degfree <- length(control)-1
pval <- pt(tval, df=degfree) #one-tailed T test
result <- data.frame(t = tval, df = degfree, p=pval)
return(result)
}
table_list <- list()
all_tables <- data.frame()
for (i in 1:length(metric)){
t_statistics <- list()
t_prob <- list()
result <- data.frame()
for (n in 1:nrow(test_samples)){
result <- CrawfordHowell(test_samples[[metric[i]]][n], healthy_popul[[metric[i]]])
t_statistics <- append(t_statistics, result[1])
t_prob <- append(t_prob, result[3])
}
t_test_results <- test_samples[, c("sample_id", "condition")]
t_test_results$metric <- test_samples[[metric[i]]]
t_test_results$t_statistic <- unlist(t_statistics)
t_test_results$t_probability <- unlist(t_prob)
t_test_results$t_probability <- round(t_test_results$t_probability, digits=3)
table_list[[i]] <- t_test_results
all_tables_next <- data.frame(table1(~ t_probability | condition, data=t_test_results, overall=F, render.continuous=c("Mean (Min, Max)"="MEAN (MIN, MAX)")))
all_tables <- rbind(all_tables, all_tables_next)
}
# Loop through each row of the merged data frame and add names of metrics
replacement_index <- 0
for (i in 1:nrow(all_tables)) {
# Check if the value in the first column is "t_probability"
if (all_tables[i, 1] == "t_probability") {
# Calculate the index for replacement from the replacement list
replacement_index <- replacement_index + 1
# Substitute the value with the replacement value
all_tables[i, 1] <- metric[replacement_index]
}
}
rows_to_remove <- grepl("^\\(N\\=?", all_tables[,2])
rows_to_remove[1] <- FALSE
all_tables <- all_tables[!rows_to_remove, ]
list_count <- list()
for (i in 1:length(metric)){
max_CDI <- max( table_list[[i]][table_list[[i]]$condition == "CDI" ,]$t_probability)
lower_than_CDI <- sum(table_list[[i]][ table_list[[i]]$condition == "healthy" ,]$t_probability < max_CDI)
list_count <- append(list_count, lower_than_CDI)
}
overlap_df <- data.frame(Parameter = metric, Overlaped_samples = unlist(list_count))
library(writexl)
write_xlsx(all_tables, here("03_plots_and_tables", "t_test.xlsx"))
all_tables %>% flextable()
p<- vector("list", length(metric))
for (i in 1:length(metric)){
p[[i]] <- ggplot(table_list[[i]], aes(x=t_probability, color=condition)) +
#geom_histogram(stat="bin", bins=40, position=position_dodge())+
geom_density( adjust = 1/6) +
geom_hline(yintercept=0, colour="white", size=0.5) +
ggtitle(metric[i])+
theme(legend.position = "none", plot.title = element_text(size=10)) +
xlab("")
}
grid.arrange(p[[1]], p[[2]], p[[3]], p[[4]], p[[5]], p[[6]],p[[7]], p[[8]],p[[9]], p[[10]], ncol=4)
p<- vector("list", length(metric))
for (i in 1:length(metric)){
p[[i]] <- ggplot(table_list[[i]], aes(x=t_probability, fill=condition)) +
geom_histogram(stat="bin", bins=40, position= "identity", alpha=0.7)+
#geom_density() +
xlab("")+
ylab("")+
ggtitle(metric[i])+
theme(legend.position = "none", plot.title = element_text(size=10)) +
xlab("")+
ylab("")+
ggtitle(metric[i])
}
grid.arrange(p[[1]], p[[2]], p[[3]], p[[4]], p[[5]], p[[6]],p[[7]], p[[8]],p[[9]], p[[10]], ncol=4)
mean_healthy <- mean(healthy_popul$strong)
SD_healthy <- sd(healthy_popul$strong)
t_statistics <- list()
t_prob <- list()
for (n in 1:nrow(test_samples)){
x <- test_samples$strong[n]
t_stat_x <- (x-mean_healthy)/(SD_healthy*sqrt((nrow(healthy_popul)+1)/nrow(healthy_popul)))
t_statistics <- append(t_statistics, t_stat_x)
t_prob_x <- pt(t_stat_x, df=nrow(healthy_popul)-1, lower.tail=FALSE)
t_prob <- append(t_prob, t_prob_x)
}
t_test_results <- test_samples[, c("sample_id", "strong", "condition")]
t_test_results$t_statistic <- unlist(t_statistics)
t_test_results$t_probability <- unlist(t_prob)
table1(~ strong + t_probability | condition, data=t_test_results, caption = "Results for alpha metric: strong")
## First option - mix donor samples from CDI data set and stool donor data set and saple control population from this
set.seed(1)
all_healthy_donors <- rbind.fill(hospital_donor, hospital_CDI[hospital_CDI$condition=="donor",])
all_healthy_donors[all_healthy_donors == "healthy_donors"] <- 'donor'
#use 70% of dataset as healthy population and 30% as healthy samples to test
sample <- sample(c(TRUE, FALSE), nrow(hospital_donor), replace=TRUE, prob=c(0.7,0.3))
healthy_popul  <- hospital_donor[sample, ]
healthy_test   <- hospital_donor[!sample, ]
nrow(healthy_popul)
nrow(healthy_test)
# samples to test
test_samples <- rbind.fill(healthy_test, hospital_CDI[hospital_CDI$condition!="donor",])
test_samples[test_samples == "healthy_donors"] <- 'donor'
table(healthy_popul$condition)
table(test_samples$condition)
nrow(test_samples)
# Second option - use stool biobank data set as control
healthy_popul <- hospital_donor
test_samples <- hospital_CDI
# modified t-test for upper tail
CrawfordHowell_2 <- function(case, control){
tval <- (case - mean(control)) / (sd(control)*sqrt((length(control)+1) / length(control)))
degfree <- length(control)-1
pval <- pt(tval, df=degfree, lower.tail=FALSE)
result <- data.frame(t = tval, df = degfree, p=pval)
return(result)
}
all_tables_2 <- data.frame()
table_list_2 <-  list()
for (i in 1:length(metric)){
t_statistics <- list()
t_prob <- list()
result <- data.frame()
for (n in 1:nrow(test_samples)){
if(metric[i] != "gini_index" & metric[i] != "strong"){
result <- CrawfordHowell(test_samples[[metric[i]]][n], healthy_popul[[metric[i]]])
} else {
result <- CrawfordHowell_2(test_samples[[metric[i]]][n], healthy_popul[[metric[i]]])
}
t_statistics <- append(t_statistics, result[1])
t_prob <- append(t_prob, result[3])
}
t_test_results <- test_samples[, c("sample_id", "condition")]
t_test_results$metric <- test_samples[[metric[i]]]
t_test_results$t_statistic <- unlist(t_statistics)
t_test_results$t_probability <- unlist(t_prob)
t_test_results$t_probability <- round(t_test_results$t_probability, digits=3)
table_list_2[[i]] <- t_test_results
all_tables_next <- data.frame(table1(~ t_probability | condition, data=t_test_results, overall=F, render.continuous=c("Mean (Min, Max)"="MEAN (MIN, MAX)")))
all_tables_2 <- rbind(all_tables_2, all_tables_next)
}
# Loop through each row of the merged data frame and add names of metrics
replacement_index <- 0
for (i in 1:nrow(all_tables_2)) {
# Check if the value in the first column is "t_probability"
if (all_tables_2[i, 1] == "t_probability") {
# Calculate the index for replacement from the replacement list
replacement_index <- replacement_index + 1
# Substitute the value with the replacement value
all_tables_2[i, 1] <- metric[replacement_index]
}
}
rows_to_remove <- grepl(c("^\\(N\\=?"), all_tables_2[,2])
rows_to_remove[1] <- FALSE
all_tables_2 <- all_tables_2[!rows_to_remove, ]
library(writexl)
write_xlsx(all_tables_2, here("03_plots_and_tables", "t_test_hospital.xlsx"))
all_tables_2 %>% flextable()
p<- vector("list", length(metric))
for (i in 1:length(metric)){
p[[i]] <- ggplot(table_list_2[[i]], aes(x=t_probability, color=condition)) +
geom_density(adjust = 1/6) +
ggtitle(metric[i])+
theme(legend.position = "none", plot.title = element_text(size=10)) +
xlab("")
}
grid.arrange(p[[1]], p[[2]], p[[3]], p[[4]], p[[5]], p[[6]],p[[7]], p[[8]],p[[9]], p[[10]], ncol=4)
p<- vector("list", length(metric))
for (i in 1:length(metric)){
p[[i]] <- ggplot(table_list_2[[i]], aes(x=t_probability, fill=condition)) +
geom_histogram(stat="bin", bins=40, position= "identity", alpha=0.7)+
#geom_density() +
xlab("")+
ylab("")+
ggtitle(metric[i])+
theme(legend.position = "none", plot.title = element_text(size=10)) +
xlab("")+
ylab("")+
ggtitle(metric[i])
}
grid.arrange(p[[1]], p[[2]], p[[3]], p[[4]], p[[5]], p[[6]],p[[7]], p[[8]],p[[9]], p[[10]], ncol=4)
list_count_pre <- list()
list_count_post <- list()
for (i in 1:length(metric)){
max_CDIpre <- max( table_list[[i]][table_list[[i]]$condition == "CDIpre" ,]$t_probability)
max_CDIpost <- max( table_list[[i]][table_list[[i]]$condition == "CDIpost" ,]$t_probability)
lower_than_CDIpre <- sum(table_list[[i]][ table_list[[i]]$condition == "donor" ,]$t_probability < max_CDIpre)
lower_than_CDIpost <- sum(table_list[[i]][ table_list[[i]]$condition == "donor" ,]$t_probability < max_CDIpost)
list_count_pre <- append(list_count_pre, lower_than_CDIpre)
list_count_post <- append(list_count_post, lower_than_CDIpost)
}
overlap_df_2 <- data.frame(Parameter = metric, Overlaped_CDIpre = unlist(list_count_pre), Overlaped_CDIpost = unlist(list_count_post))
overlap_df_2
list_count_pre <- list()
list_count_post <- list()
for (i in 1:length(metric)){
max_CDIpre <- max( table_list[[i]][table_list[[i]]$condition == "Cdif_pre" ,]$t_probability)
max_CDIpost <- max( table_list[[i]][table_list[[i]]$condition == "Cdif_post" ,]$t_probability)
lower_than_CDIpre <- sum(table_list[[i]][ table_list[[i]]$condition == "donor" ,]$t_probability < max_CDIpre)
lower_than_CDIpost <- sum(table_list[[i]][ table_list[[i]]$condition == "donor" ,]$t_probability < max_CDIpost)
list_count_pre <- append(list_count_pre, lower_than_CDIpre)
list_count_post <- append(list_count_post, lower_than_CDIpost)
}
overlap_df_2 <- data.frame(Parameter = metric, Overlaped_CDIpre = unlist(list_count_pre), Overlaped_CDIpost = unlist(list_count_post))
overlap_df_2
table(table_list[[1]]$condition)
## First option - mix donor samples from CDI data set and stool donor data set and saple control population from this
set.seed(1)
all_healthy_donors <- rbind.fill(hospital_donor, hospital_CDI[hospital_CDI$condition=="donor",])
all_healthy_donors[all_healthy_donors == "healthy_donors"] <- 'donor'
#use 70% of dataset as healthy population and 30% as healthy samples to test
sample <- sample(c(TRUE, FALSE), nrow(hospital_donor), replace=TRUE, prob=c(0.7,0.3))
healthy_popul  <- hospital_donor[sample, ]
healthy_test   <- hospital_donor[!sample, ]
nrow(healthy_popul)
nrow(healthy_test)
# samples to test
test_samples <- rbind.fill(healthy_test, hospital_CDI[hospital_CDI$condition!="donor",])
test_samples[test_samples == "healthy_donors"] <- 'donor'
table(healthy_popul$condition)
table(test_samples$condition)
nrow(test_samples)
# Second option - use stool biobank data set as control
healthy_popul <- hospital_donor
test_samples <- hospital_CDI
# modified t-test for upper tail
CrawfordHowell_2 <- function(case, control){
tval <- (case - mean(control)) / (sd(control)*sqrt((length(control)+1) / length(control)))
degfree <- length(control)-1
pval <- pt(tval, df=degfree, lower.tail=FALSE)
result <- data.frame(t = tval, df = degfree, p=pval)
return(result)
}
all_tables_2 <- data.frame()
table_list_2 <-  list()
for (i in 1:length(metric)){
t_statistics <- list()
t_prob <- list()
result <- data.frame()
for (n in 1:nrow(test_samples)){
if(metric[i] != "gini_index" & metric[i] != "strong"){
result <- CrawfordHowell(test_samples[[metric[i]]][n], healthy_popul[[metric[i]]])
} else {
result <- CrawfordHowell_2(test_samples[[metric[i]]][n], healthy_popul[[metric[i]]])
}
t_statistics <- append(t_statistics, result[1])
t_prob <- append(t_prob, result[3])
}
t_test_results <- test_samples[, c("sample_id", "condition")]
t_test_results$metric <- test_samples[[metric[i]]]
t_test_results$t_statistic <- unlist(t_statistics)
t_test_results$t_probability <- unlist(t_prob)
t_test_results$t_probability <- round(t_test_results$t_probability, digits=3)
table_list_2[[i]] <- t_test_results
all_tables_next <- data.frame(table1(~ t_probability | condition, data=t_test_results, overall=F, render.continuous=c("Mean (Min, Max)"="MEAN (MIN, MAX)")))
all_tables_2 <- rbind(all_tables_2, all_tables_next)
}
# Loop through each row of the merged data frame and add names of metrics
replacement_index <- 0
for (i in 1:nrow(all_tables_2)) {
# Check if the value in the first column is "t_probability"
if (all_tables_2[i, 1] == "t_probability") {
# Calculate the index for replacement from the replacement list
replacement_index <- replacement_index + 1
# Substitute the value with the replacement value
all_tables_2[i, 1] <- metric[replacement_index]
}
}
rows_to_remove <- grepl(c("^\\(N\\=?"), all_tables_2[,2])
rows_to_remove[1] <- FALSE
all_tables_2 <- all_tables_2[!rows_to_remove, ]
library(writexl)
write_xlsx(all_tables_2, here("03_plots_and_tables", "t_test_hospital.xlsx"))
all_tables_2 %>% flextable()
list_count_pre <- list()
list_count_post <- list()
table(table_list[[1]]$condition)
for (i in 1:length(metric)){
max_CDIpre <- max( table_list[[i]][table_list[[i]]$condition == "Cdif_pre" ,]$t_probability)
max_CDIpost <- max( table_list[[i]][table_list[[i]]$condition == "Cdif_post" ,]$t_probability)
lower_than_CDIpre <- sum(table_list[[i]][ table_list[[i]]$condition == "donor" ,]$t_probability < max_CDIpre)
lower_than_CDIpost <- sum(table_list[[i]][ table_list[[i]]$condition == "donor" ,]$t_probability < max_CDIpost)
list_count_pre <- append(list_count_pre, lower_than_CDIpre)
list_count_post <- append(list_count_post, lower_than_CDIpost)
}
overlap_df_2 <- data.frame(Parameter = metric, Overlaped_CDIpre = unlist(list_count_pre), Overlaped_CDIpost = unlist(list_count_post))
list_count_pre <- list()
list_count_post <- list()
for (i in 1:length(metric)){
max_CDIpre <- max( table_list_2[[i]][table_list_2[[i]]$condition == "Cdif_pre" ,]$t_probability)
max_CDIpost <- max( table_list_2[[i]][table_list_2[[i]]$condition == "Cdif_post" ,]$t_probability)
lower_than_CDIpre <- sum(table_list_2[[i]][ table_list_2[[i]]$condition == "donor" ,]$t_probability < max_CDIpre)
lower_than_CDIpost <- sum(table_list_2[[i]][ table_list_2[[i]]$condition == "donor" ,]$t_probability < max_CDIpost)
list_count_pre <- append(list_count_pre, lower_than_CDIpre)
list_count_post <- append(list_count_post, lower_than_CDIpost)
}
overlap_df_2 <- data.frame(Parameter = metric, Overlaped_CDIpre = unlist(list_count_pre), Overlaped_CDIpost = unlist(list_count_post))
overlap_df_2
overlap_df
write_xlsx(overlap_df, here("03_plots_and_tables", "overlap_1.xlsx"))
overlap_df
write_xlsx(overlap_df_2, here("03_plots_and_tables", "overlap_2.xlsx"))
overlap_df_2 <- data.frame(Parameter = metric, Overlaped_CDIpre = unlist(list_count_pre), Overlaped_CDIpost = unlist(list_count_post))
overlap_df_2

bold(~ p.value < 0.05, 4) %>%
bold(~ p.adjusted < 0.05, 5) %>%
add_header_lines(values = "Results of the Mann-Whitney-Wilcoxon test for distributions of different groups of Crhohn's disease patients")
write_xlsx(test_CDI_healthy, here("03_plots_and_tables", "CDI_AGP.xlsx"))
table(CDI_FMT$disease_state)
table(CDI_FMT$animations_subject)
CDI_FMT$animations_subject[CDI_FMT$animations_subject == "CD1"] <-'subject_1'
CDI_FMT$animations_subject[CDI_FMT$animations_subject == "CD2"] <-'subject_2'
CDI_FMT$animations_subject[CDI_FMT$animations_subject == "CD3"] <-'subject_3'
CDI_FMT$animations_subject[CDI_FMT$animations_subject == "CD4"] <-'subject_4'
progression <- vector('list', length(metric))
for (i in 1:length(metric)){
progression[[i]] <- CDI_FMT %>% ggplot(aes(x=day_since_fmt, y= .data[[metric[i]]], color= CDI_FMT$animations_subj)) +
geom_line()+
geom_point(size=1)+
ylab(label_fun(metric[i]))+
xlab("Day since FMT")+
facet_wrap(dplyr::vars(CDI_FMT$animations_subject), ncol=2)
}
progression
CDI_FMT_a <- CDI_FMT
for(i in 1:nrow(CDI_FMT_a)) {
if(CDI_FMT_a$day_since_fmt[i] < 1 ){
CDI_FMT_a$day_since_fmt[i] <- -1
}
}
for (i in 1:length(metric)) {
progression[[i]] <- CDI_FMT_a %>% ggplot(aes(x=day_since_fmt, y= .data[[metric[i]]], color =CDI_FMT$animations_subj)) +
geom_line()+
geom_point(size=1) +
geom_vline(xintercept = 0, linetype = "dashed")+
theme_classic() +
theme(legend.position="none", axis.title.y=element_text(size=10), axis.title.x=element_text(size=15), title =element_text(size=10)) +
# ggtitle(label_fun(metric[i]))+
# ylab("")+
ylab(label_fun(metric[i]))+
xlab("")+
scale_color_manual(values=c('#a6611a','#dfc27d','#80cdc1','#018571'))
}
grid.arrange(progression[[2]], progression[[7]], ncol=1, bottom = textGrob("Day since FMT", gp = gpar(fontsize = 15)))
grid.arrange(progression[[2]], progression[[7]], progression[[9]], ncol=1, bottom = textGrob("Day since FMT", gp = gpar(fontsize = 12)))
# grid.arrange(progression[[1]], progression[[2]], progression[[3]], progression[[4]], progression[[5]], progression[[6]], ncol=2)
# grid.arrange(progression[[7]], progression[[8]], progression[[9]], progression[[10]], ncol=2, nrow=3)
for (i in 1:length(metric)) {
progression[[i]] <- CDI_FMT[CDI_FMT$animations_subject == "subject_1",] %>% ggplot(aes(x=day_since_fmt, y= .data[[metric[i]]])) +
geom_line(color='#018571')+
geom_point(size=1, color='#018571') +
theme_classic() +
theme(legend.position="none", axis.title.y=element_text(size=12), axis.title.x=element_text(size=12)) +
ylab(label_fun(metric[i]))+
xlab("")
#scale_color_brewer(palette="Set3")
#scale_color_manual(values=c('#a6611a','#dfc27d','#80cdc1','#018571'))
}
grid.arrange(progression[[2]], progression[[7]], ncol=1)
grid.arrange(progression[[1]], progression[[2]], progression[[3]], progression[[4]], progression[[5]], progression[[6]], ncol=3)
grid.arrange(progression[[7]], progression[[8]], progression[[9]], progression[[10]], ncol=3, bottom = textGrob("Day since FMT", gp = gpar(fontsize = 12)))
#all_tables_next <- data.frame(table1(~ t_probability | condition, data=t_test_results, overall=F, render.continuous=c("Mean (Min, Max)"="MEAN (MIN, MAX)")))
table1(~ chao1 + margalef + menhinick + fisher_alpha + faith_pd + gini_index + strong + pielou_evenness + shannon_entropy + simpson | animations_subject, data=CDI_FMT, overall=F, render.continuous=c("Min"="MIN", "Max"="MAX", "percent. difference" = "((MAX-MIN)/MIN)*100"))
subjects <- unique(CDI_FMT$animations_subject)
data <- CDI_FMT[CDI_FMT$animations_subject == subjects[1],]
for (i in 1:length(metric)) {
progression[[i]] <- data %>% ggplot(aes(x=day_since_fmt, y= .data[[metric[i]]])) +
geom_line(color='#a6611a')+
geom_point(size=1, color='#a6611a')+
ylab(label_fun(metric[i]))+
xlab("Day since FMT")+
theme_classic()
}
grid.arrange(progression[[1]], progression[[2]], progression[[3]], progression[[4]], progression[[5]], progression[[6]], progression[[7]], progression[[8]], progression[[9]], progression[[10]], ncol=3)
table(FMT_IBD_CDI$condition)
table(FMT_IBD_CDI$day_since_fmt)
violin_trans_2 <- vector('list', length(metric))
for (i in 1:length(metric)){
mean_line <- FMT_IBD_CDI %>% dplyr::group_by(condition, day_since_fmt) %>% dplyr::summarise(grp_mean = mean(.data[[metric[i]]]))
violin_trans_2[[i]] <- FMT_IBD_CDI %>%
mutate(across(day_since_fmt, factor, levels=c("-1","7","28","NA-Donor"))) %>%
ggplot(aes(x = .data[[metric[i]]], y = day_since_fmt, color = day_since_fmt, fill = day_since_fmt)) +
geom_violin()+
geom_boxplot(width=0.1, color="grey", alpha=0.2) +
geom_vline(data = mean_line, aes(xintercept = grp_mean, color = day_since_fmt), linetype = "dashed")+
xlab(label_fun(metric[i]))+
ylab("") +
facet_wrap(dplyr::vars(condition), nrow=1)+
theme(legend.position="none")
}
#plots for Shannon entropy
violin_trans_2
cond <- c("CDI + UC", "CDI", "CDI + CD")
test_CDI_trans <- list()
table <- list()
for (i in 1:length(cond)){
FMT_IBD_CDI_1 <- FMT_IBD_CDI %>%
filter(condition == cond[i])
test_CDI_trans <- do_wilcox_test(FMT_IBD_CDI_1, "day_since_fmt")
table <- test_CDI_trans %>%
# add_column(p.adjusted = round(p.adjust(test_CDI_trans$p.value, "fdr"), digits=5), .after='p.value') %>%
add_column(p.adjusted = p.adjust(test_CDI_trans$p.value, "fdr"), .after='p.value') %>%
flextable() %>%
bold(~ p.value < 0.05, 4) %>%
bold(~ p.adjusted < 0.05, 5) %>%
add_header_lines(values = paste("Results of the Mann-Whitney-Wilcoxon test for condition:", cond[i], sep = " "))
print(table)
test_CDI_trans <- list()
}
sessionInfo()
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(grid)
library(plyr)
#install.packages('cowplot')
library(cowplot)
library(tibble)
library(flextable)
#install.packages('nortest')
library(nortest)
#install.packages('PerformanceAnalytics')
library(PerformanceAnalytics)
library(corrplot)
library(RColorBrewer)
library(here)
#AGP <- read.csv(here("01_tidy_data", "AGP_all.csv.gz"), header = TRUE, sep = ",")
all_healthy <- read.csv(here("01_tidy_data", "AGP_healthy.csv.gz"), header = TRUE, sep = ",")
#nrow(AGP)
nrow(all_healthy)
label_fun <- function(x){
if (x == "shannon_entropy"){y <- "Shannon entropy"} else if (x =="chao1"){y <- "Chao1"} else if (x == "menhinick"){y <- "Menhinick"} else if (x == "margalef"){y <- "Margalef"} else if (x == "fisher_alpha"){y <- "Fisher alpha"} else if (x == "simpson"){y <- "Simpson"} else if (x == "gini_index"){y <- "Gini index"} else if (x == "strong"){y <- "Strong dominance"} else if (x == "pielou_evenness"){y <- "Pielou evenness"} else if (x == "faith_pd"){y <- "Faith PD"}
return(y)
}
metric <- c("chao1", "margalef", "menhinick", "fisher_alpha", "faith_pd", "gini_index", "strong", "pielou_evenness", "shannon_entropy", "simpson")
qual_col_pals <- brewer.pal.info[brewer.pal.info$category == 'qual',]
colors <- unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
metric2 <- c("gini_index", "strong", "shannon_entropy", "simpson", "pielou_evenness", "chao1", "faith_pd", "fisher_alpha", "menhinick", "margalef")
histo <- vector('list', length(metric2))
for (i in 1:length(metric2)){
histo[[i]] <- all_healthy %>% ggplot(aes(x = .data[[metric2[i]]])) +
geom_histogram(aes(y=..density..), colour="black", fill="white", bins=30)+
geom_density(alpha=.2, fill=colors[i]) +
ylab(label = "") +
xlab(label_fun(metric2[i])) +
theme_classic()+
theme(axis.title.x = element_text(size=14))
}
grid.arrange(histo[[1]], histo[[2]],histo[[3]], histo[[4]],histo[[5]], histo[[6]],histo[[7]], histo[[8]],histo[[9]], histo[[10]], ncol=3, left = textGrob("density", rot = 90, gp = gpar(fontsize = 14)))
pval_sp <- list()
stat_sp <- list()
for (i in 1:length(metric)){
pval_sp[i] <- shapiro.test(all_healthy[[metric[i]]])[2]
stat_sp[i] <- shapiro.test(all_healthy[[metric[i]]])[1]
}
stat_sp <- lapply(stat_sp, unname) %>% unlist(stat_sp)
pval_sp <- unlist(pval_sp)
table_saphiro <- data.frame(metric=metric, statistic=stat_sp, p.value=pval_sp)
#table_saphiro$p.value <- round(table_saphiro$p.value, digits = 16)
skewness_list <- list()
kurtosis_list <- list()
for(i in 1:length(metric)){
#calculate skewness
sk <- skewness(all_healthy[[metric[i]]])
skewness_list <- append(skewness_list, sk)
#calculate kurtosis
kr <- kurtosis(all_healthy[[metric[i]]])
kurtosis_list <- append(kurtosis_list, kr)
}
table_saphiro$skewness <- unlist(skewness_list)
table_saphiro$kurtosis <- unlist(kurtosis_list)
table_saphiro %>%
arrange(desc(statistic)) %>%
flextable() %>%
add_header_lines(values = "Normality test (Shapiro-Wilk), skewness and kurtosis of different metrics")
library(writexl)
write_xlsx(table_saphiro, here("03_plots_and_tables", "skewness_table.xlsx"))
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(plyr)
library(cowplot)
library(tibble)
library(flextable)
library(nortest)
library(corrplot)
library(PerformanceAnalytics)
library(RColorBrewer)
library(here)
library(ROSE)
library(randomForest)
library(caret)
library(rstatix)
library(gridExtra)
library(grid)
#install.packages("moments")
library(moments)
library(writexl)
metric <- c("chao1", "margalef", "menhinick", "fisher_alpha", "faith_pd", "gini_index", "strong", "pielou_evenness", "shannon_entropy", "simpson")
all_healthy <- read.csv(here("01_tidy_data", "AGP_healthy.csv.gz"), header = TRUE, sep = ",")
IBD <- read.csv(here("01_tidy_data", "IBD.csv.gz"), header = TRUE, sep = ",")
UC <- read.csv(here("01_tidy_data", "UC.csv.gz"), header = TRUE, sep = ",")
CD <- read.csv(here("01_tidy_data", "CD_2.csv.gz"), header = TRUE, sep = ",")
CDI <- read.csv(here("01_tidy_data", "ncbi_CDI.csv.gz"), header = TRUE, sep = ",")
hospital_CDI <- read.csv(here("01_tidy_data", "hosp_CDI.csv.gz"), header = TRUE, sep = ",")
hospital_donor <- read.csv(here("01_tidy_data", "hosp_donor.csv.gz"), header = TRUE, sep = ",")
all_healthy <- dplyr::select(all_healthy, sample_id, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, pielou_evenness, gini_index, strong, simpson, faith_pd, condition)
CD_merge <- CD %>%
filter(condition != "not applicable")
CD_merge$condition[CD_merge$condition=="control"] <- "healthy"
CD_merge$condition[CD_merge$condition=="crohns"] <- "CD"
healthy_disease <- rbind.fill(all_healthy, IBD, UC, CD_merge, CDI)
# extract only allpha metrics and condition columns
healthy_disease <- dplyr::select(healthy_disease, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, gini_index, strong, pielou_evenness, faith_pd, condition)
# for random forest
healthy_disease$healthy_or_not[healthy_disease$condition == "healthy"] <- "healthy"
healthy_disease$healthy_or_not[healthy_disease$condition != "healthy"] <- "unhealthy"
healthy_disease$healthy_or_not<- as.factor(healthy_disease$healthy_or_not)
healthy_disease$condition<- as.factor(healthy_disease$condition)
table(healthy_disease$condition)
table(healthy_disease$healthy_or_not)
healthy_IBD <- rbind.fill(all_healthy, IBD, UC, CD_merge)
# extract only allpha metrics and condition columns
healthy_IBD <- dplyr::select(healthy_IBD, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, gini_index, strong, pielou_evenness, faith_pd, condition)
# for random forest
healthy_IBD$healthy_or_not[healthy_IBD$condition == "healthy"] <- "healthy"
healthy_IBD$healthy_or_not[healthy_IBD$condition != "healthy"] <- "unhealthy"
healthy_IBD$healthy_or_not<- as.factor(healthy_IBD$healthy_or_not)
healthy_IBD$condition<- as.factor(healthy_IBD$condition)
table(healthy_IBD$condition)
table(healthy_IBD$healthy_or_not)
healthy_CDI <- rbind.fill(all_healthy, CDI)
# extract only allpha metrics and condition columns
healthy_CDI <- dplyr::select(healthy_CDI, shannon_entropy, chao1, menhinick, margalef, fisher_alpha, simpson, gini_index, strong, pielou_evenness, faith_pd, condition)
# for random forest
healthy_CDI$healthy_or_not[healthy_CDI$condition == "healthy"] <- "healthy"
healthy_CDI$healthy_or_not[healthy_CDI$condition != "healthy"] <- "unhealthy"
healthy_CDI$healthy_or_not<- as.factor(healthy_CDI$healthy_or_not)
healthy_CDI$condition<- as.factor(healthy_CDI$condition)
table(healthy_CDI$condition)
table(healthy_CDI$healthy_or_not)
hospital_CDI_pre_FMT <- hospital_CDI %>%
filter(FMT_pre_post == "pre")
compare_hospital <- rbind.fill(hospital_donor, hospital_CDI_pre_FMT)
compare_hospital$condition <- as.factor(compare_hospital$condition)
# Sizes of each dataset
table(compare_hospital$condition)
# Let's make training and testing subset of data
#make this example reproducible
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(healthy_disease), replace=TRUE, prob=c(0.7,0.3))
train  <- healthy_disease[sample, ]
test   <- healthy_disease[!sample, ]
table(train$healthy_or_not)
# condition groups are unbalanced. We will solve this by undersampling
under <- ovun.sample(healthy_or_not~., data=train, method = "under", p=0.5)
train <- under$data
table(train$healthy_or_not)
richness <- c("chao1", "margalef", "menhinick", "fisher_alpha", "faith_pd")
evenness <- c("gini_index", "strong", "pielou_evenness", "shannon_entropy", "simpson")
results_accuracy_all <- data.frame(model = character(0), accuracy = numeric(0) )
model_all_1 <- randomForest(condition ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
model_all_2 <- randomForest(healthy_or_not ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
prediction_all_1 <- predict(model_all_1, test)
confusion_matrix <- confusionMatrix(prediction_all_1, test$condition)
accuracy_all_model_1 <- confusion_matrix$overall["Accuracy"]
prediction_all_2 <- predict(model_all_2, test)
confusion_matrix <- confusionMatrix(prediction_all_2, test$healthy_or_not)
accuracy_all_model_2 <- confusion_matrix$overall["Accuracy"]
for (a in richness){
for (b in evenness){
formula_1 <- as.formula(sprintf("%s ~ %s + %s", "condition", a, b))
model_1 <- randomForest(formula_1, data = train, importance=TRUE)
formula_2 <- as.formula(sprintf("%s ~ %s + %s", "healthy_or_not", a, b))
model_2 <- randomForest(formula_2, data = train, importance=TRUE)
# Calculating accuracy
prediction_1 <- predict(model_1, test)
confusion_matrix <- confusionMatrix(prediction_1, test$condition)
accuracy_1 <- confusion_matrix$overall["Accuracy"]
prediction_2 <- predict(model_2, test)
confusion_matrix <- confusionMatrix(prediction_2, test$healthy_or_not)
accuracy_2 <- confusion_matrix$overall["Accuracy"]
new_row <- c(model = sprintf("%s + %s", a, b), accuracy_condition = accuracy_1, accuracy_healthy_or_not = accuracy_2)
results_accuracy_all <- rbind(results_accuracy_all, new_row)
}
}
names(results_accuracy_all)[1] <- 'model'
names(results_accuracy_all)[2] <- 'accuracy_condition'
names(results_accuracy_all)[3] <- 'accuracy_healthy_or_not'
results_accuracy_all[nrow(results_accuracy_all)+1,] <- c("all alpha metrics", accuracy_all_model_1, accuracy_all_model_2)
results_accuracy_all$accuracy_condition <- as.numeric(results_accuracy_all$accuracy_condition)
results_accuracy_all$accuracy_healthy_or_not <- as.numeric(results_accuracy_all$accuracy_healthy_or_not)
results_accuracy_all <- results_accuracy_all[order(-results_accuracy_all$accuracy_condition),]
results_accuracy_all[1:10,] %>%
flextable() %>%
add_header_lines(values = "Accuracy of random forest classifier trained on all datasets in differnet models")
write_xlsx(results_accuracy_all, here("03_plots_and_tables", "accuracy_all.xlsx"))
# Let's make training and testing subset of data
#make this example reproducible
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(healthy_IBD), replace=TRUE, prob=c(0.7,0.3))
train  <- healthy_IBD[sample, ]
test   <- healthy_IBD[!sample, ]
table(train$healthy_or_not)
# condition groups are unbalanced. We will solve this by undersampling
under <- ovun.sample(healthy_or_not~., data=train, method = "under", p=0.5)
train <- under$data
table(train$healthy_or_not)
table(train$condition)
results_accuracy_IBD <- data.frame(model = character(0), accuracy_condition = numeric(0), accuracy_healthy_or_not = numeric(0) )
model_IBD_1 <- randomForest(condition ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
model_IBD_2 <- randomForest(healthy_or_not ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
prediction_IBD_1 <- predict(model_IBD_1, test)
confusion_matrix <- confusionMatrix(prediction_IBD_1, test$condition)
accuracy_IBD_model_1 <- confusion_matrix$overall["Accuracy"]
prediction_IBD_2 <- predict(model_IBD_2, test)
confusion_matrix <- confusionMatrix(prediction_IBD_2, test$healthy_or_not)
accuracy_IBD_model_2 <- confusion_matrix$overall["Accuracy"]
for (a in richness){
for (b in evenness){
formula_1 <- as.formula(sprintf("%s ~ %s + %s", "condition", a, b))
model_1 <- randomForest(formula_1, data = train, importance=TRUE)
formula_2 <- as.formula(sprintf("%s ~ %s + %s", "healthy_or_not", a, b))
model_2 <- randomForest(formula_2, data = train, importance=TRUE)
# Calculating accuracy
prediction_1 <- predict(model_1, test)
confusion_matrix <- confusionMatrix(prediction_1, test$condition)
accuracy_1 <- confusion_matrix$overall["Accuracy"]
prediction_2 <- predict(model_2, test)
confusion_matrix <- confusionMatrix(prediction_2, test$healthy_or_not)
accuracy_2 <- confusion_matrix$overall["Accuracy"]
new_row <- c(model = sprintf("%s + %s", a, b), accuracy_condition = accuracy_1, accuracy_healthy_or_not = accuracy_2)
results_accuracy_IBD <- rbind(results_accuracy_IBD, new_row)
}
}
names(results_accuracy_IBD)[1] <- 'model'
names(results_accuracy_IBD)[2] <- 'accuracy_condition'
names(results_accuracy_IBD)[3] <- 'accuracy_healthy_or_not'
results_accuracy_IBD[nrow(results_accuracy_IBD)+1,] <- c("all alpha metrics", accuracy_IBD_model_1, accuracy_IBD_model_2)
results_accuracy_IBD$accuracy_condition <- as.numeric(results_accuracy_IBD$accuracy_condition)
results_accuracy_IBD$accuracy_healthy_or_not <- as.numeric(results_accuracy_IBD$accuracy_healthy_or_not)
results_accuracy_IBD <- results_accuracy_IBD[order(-results_accuracy_IBD$accuracy_condition),]
results_accuracy_IBD[1:10,] %>%
flextable() %>%
add_header_lines(values = "Accuracy of random forest classifier trained on IBD and healthy datasets in differnet models")
write_xlsx(results_accuracy_IBD, here("03_plots_and_tables", "accuracy_IBD.xlsx"))
# Let's make training and testing subset of data
#make this example reproducible
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(healthy_CDI), replace=TRUE, prob=c(0.7,0.3))
train  <- healthy_CDI[sample, ]
test   <- healthy_CDI[!sample, ]
table(train$condition)
# condition groups are unbalanced. We will solve this by undersampling
under <- ovun.sample(condition~., data=train, method = "under", p=0.5)
train <- under$data
table(train$condition)
results_accuracy_CDI <- data.frame(model = character(0), accuracy = numeric(0))
model_all <- randomForest(condition ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
prediction_CDI_all <- predict(model_all, test)
confusion_matrix <- confusionMatrix(prediction_CDI_all, test$condition)
accuracy_CDI_all <- confusion_matrix$overall["Accuracy"]
for (a in richness){
for (b in evenness){
formula <- as.formula(sprintf("%s ~ %s + %s", "condition", a, b))
model <- randomForest(formula, data = train, importance=TRUE)
# Calculating accuracy
prediction <- predict(model, test)
confusion_matrix <- confusionMatrix(prediction, test$condition)
accuracy <- confusion_matrix$overall["Accuracy"]
new_row <- c(model = sprintf("%s + %s", a, b), accuracy = accuracy)
results_accuracy_CDI <- rbind(results_accuracy_CDI, new_row)
}
}
names(results_accuracy_CDI)[1] <- 'model'
names(results_accuracy_CDI)[2] <- 'accuracy'
results_accuracy_CDI[nrow(results_accuracy_CDI)+1,] <- c("all alpha metrics", accuracy_CDI_all)
results_accuracy_CDI$accuracy <- as.numeric(results_accuracy_CDI$accuracy)
results_accuracy_CDI <- results_accuracy_CDI[order(-results_accuracy_CDI$accuracy),]
results_accuracy_CDI[1:10,] %>%
flextable() %>%
add_header_lines(values = "Accuracy of random forest classifier trained on CDI and healthy datasets in differnet models")
write_xlsx(results_accuracy_CDI, here("03_plots_and_tables", "accuracy_CDI.xlsx"))
model <- randomForest(condition ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = healthy_disease, importance=TRUE)
importance(model)
varImpPlot(model, main= "Mean descrease in accuracy and  Gini index over all classes")
#Conditional=True, adjusts for correlations between predictors.
i_scores <- caret::varImp(model, conditional = TRUE)
#Gathering rownames in 'var'  and converting it to the factor
#to provide 'fill' parameter for the bar chart.
i_scores <- i_scores %>% tibble::rownames_to_column("var")
i_scores$var<- i_scores$var %>% as.factor()
#Plotting the bar and polar charts for comparing variables
importance_plot <- i_scores %>% ggplot(aes(x = .data[["healthy"]], y=reorder(var, .data[["healthy"]]), fill = var)) +
geom_bar(stat = "identity", show.legend = FALSE, width = 1) +
labs(x = NULL, y = NULL, title ="Mean decrease in accuracy for condition category: healthy") +
theme_minimal() +
theme(axis.text.y = element_text(size=15)) +
# theme(axis.text.y = element_blank()) +
scale_y_discrete(labels=c("shannon_entropy"="Shannon entropy (❋)", "chao1"="Chao1 (+)", "menhinick"="Menhinick (+)", "margalef"="Margalef (+)", "fisher_alpha"="Fisher alpha (+)", "simpson"="Simpson (❋)", "gini_index"="Gini index (x)", "strong"="Strong dominance (x)", "pielou_evenness"="Pielou evenness (x)",  "faith_pd"="Faith PD (+)"))
importance_plot
# Let's make training and testing subset of data
#make this example reproducible
set.seed(1)
#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(compare_hospital), replace=TRUE, prob=c(0.7,0.3))
train  <- compare_hospital[sample, ]
test   <- compare_hospital[!sample, ]
table(train$condition)
table(test$condition)
results_accuracy_CDI_hospital <- data.frame(model = character(0), accuracy = numeric(0))
model_all_hospital <- randomForest(condition ~ shannon_entropy + chao1 + menhinick + margalef + fisher_alpha + simpson + gini_index + strong + pielou_evenness + faith_pd, data = train, importance=TRUE)
prediction_CDI_all <- predict(model_all_hospital, test)
confusion_matrix <- confusionMatrix(prediction_CDI_all, test$condition)
accuracy_CDI_all <- confusion_matrix$overall["Accuracy"]
for (a in richness){
for (b in evenness){
formula <- as.formula(sprintf("%s ~ %s + %s", "condition", a, b))
model <- randomForest(formula, data = train, importance=TRUE)
# Calculating accuracy
prediction <- predict(model, test)
confusion_matrix <- confusionMatrix(prediction, test$condition)
accuracy <- confusion_matrix$overall["Accuracy"]
new_row <- c(model = sprintf("%s + %s", a, b), accuracy = accuracy)
results_accuracy_CDI_hospital <- rbind(results_accuracy_CDI_hospital, new_row)
}
}
names(results_accuracy_CDI_hospital)[1] <- 'model'
names(results_accuracy_CDI_hospital)[2] <- 'accuracy'
results_accuracy_CDI_hospital[nrow(results_accuracy_CDI_hospital)+1,] <- c("all alpha metrics", accuracy_CDI_all)
results_accuracy_CDI_hospital$accuracy <- as.numeric(results_accuracy_CDI_hospital$accuracy)
results_accuracy_CDI <- results_accuracy_CDI[order(-results_accuracy_CDI_hospital$accuracy),]
results_accuracy_CDI_hospital[1:10,] %>%
flextable() %>%
add_header_lines(values = "Accuracy of random forest classifier trained on CDI and healthy datasets in differnet models")
write_xlsx(results_accuracy_CDI_hospital, here("03_plots_and_tables", "accuracy_CDI_hospital.xlsx"))
table(healthy_disease$healthy_or_not)
test <- list()
tibble <- tibble()
for (i in 1:length(metric)){
# Wilcoxon test
test[[i]] <- pairwise.wilcox.test(healthy_disease[[metric[i]]], healthy_disease$healthy_or_not, p.adjust.method="none") %>%
broom::tidy() %>% add_column(parameter = metric[i], .before='group1')
test[[i]]$p.value <- round(test[[i]]$p.value, digits = 16)
# Effect size
tibble_a <- healthy_disease %>% wilcox_effsize(
as.formula(sprintf("%s ~ %s", metric[i], "healthy_or_not")),
ref.group = "healthy",
paired = FALSE,
alternative = "two.sided",
ci = TRUE,
conf.level = 0.95,
ci.type = "perc",
nboot = 1000
)
tibble <- bind_rows(tibble, tibble_a)
}
tests_1 <- do.call(what = rbind, args = test)
names(tibble)[names(tibble) == '.y.'] <- 'parameter'
eff_size <- tibble[, !names(tibble) %in% c("group1", "group2")]
tests_1 <- inner_join(tests_1, eff_size , by= "parameter")
test_1_show <- tests_1 %>%
# add_column(p.adjusted = round(p.adjust(tests_1$p.value, "fdr"), 16), .after='p.value') %>%
add_column(p.adjusted = p.adjust(tests_1$p.value, "fdr"), .after='p.value') %>%
arrange(-effsize)
test_1_show %>%
flextable() %>%
bold(~ p.value < 0.05, 4) %>%
bold(~ p.adjusted < 0.05, 5) %>%
add_header_lines(values = "Results of the Wilcox test for distributions of healthy vs unhealthy samples")
#write.csv(tests_1, gzfile(here("03_plots_and_tables", "eff_size.csv")), row.names=FALSE)
#install.packages("writexl")
library(writexl)
write_xlsx(test_1_show, here("03_plots_and_tables", "eff_size.xlsx"))
test_1_show
test <- list()
tibble <- tibble()
for (i in 1:length(metric)){
# Wilcoxon test
test[[i]] <- pairwise.wilcox.test(healthy_disease[[metric[i]]], healthy_disease$healthy_or_not, p.adjust.method="none") %>%
broom::tidy() %>% add_column(parameter = metric[i], .before='group1')
# test[[i]]$p.value <- round(test[[i]]$p.value, digits = 16)
# Effect size
tibble_a <- healthy_disease %>% wilcox_effsize(
as.formula(sprintf("%s ~ %s", metric[i], "healthy_or_not")),
ref.group = "healthy",
paired = FALSE,
alternative = "two.sided",
ci = TRUE,
conf.level = 0.95,
ci.type = "perc",
nboot = 1000
)
tibble <- bind_rows(tibble, tibble_a)
}
tests_1 <- do.call(what = rbind, args = test)
names(tibble)[names(tibble) == '.y.'] <- 'parameter'
eff_size <- tibble[, !names(tibble) %in% c("group1", "group2")]
tests_1 <- inner_join(tests_1, eff_size , by= "parameter")
test_1_show <- tests_1 %>%
# add_column(p.adjusted = round(p.adjust(tests_1$p.value, "fdr"), 16), .after='p.value') %>%
add_column(p.adjusted = p.adjust(tests_1$p.value, "fdr"), .after='p.value') %>%
arrange(-effsize)
test_1_show %>%
flextable() %>%
bold(~ p.value < 0.05, 4) %>%
bold(~ p.adjusted < 0.05, 5) %>%
add_header_lines(values = "Results of the Wilcox test for distributions of healthy vs unhealthy samples")
#write.csv(tests_1, gzfile(here("03_plots_and_tables", "eff_size.csv")), row.names=FALSE)
#install.packages("writexl")
library(writexl)
write_xlsx(test_1_show, here("03_plots_and_tables", "eff_size.xlsx"))
